\documentclass[a4paper]{article}
% \documentclass[twocolumn,12pt]{article}
\usepackage{hyperref}
\usepackage{noweb}
\usepackage{amsmath}
\usepackage{microtype}
\usepackage[UKenglish]{datetime}
\usepackage{booktabs}
%\usepackage[UKenglish]{isodate}
\newdateformat{mydate}{\THEDAY{} \monthname[\THEMONTH]{} \THEYEAR}
\noweboptions{longxref,alphasubpage,subscriptidents,subscriptquotedidents,longchunks}

\usepackage[utf8]{inputenc} % Remove biblatex 'ascii' errors
\usepackage[T1]{fontenc} % Remove 'stretch' errors
%\usepackage{lmodern}
\usepackage{mathpazo} % Nice font

% % Set up formatting to look more like a modern report than an old book.
\setlength{\parindent}{0em}
\setlength{\parskip}{1em}

% Default Geometry
% \usepackage[margin=0.5in]{geometry}
% \usepackage[margin=0.5in, paperwidth=14.15in, paperheight=11.25in]{geometry} % 1280 x 1024 Monitor reading
% \usepackage[margin=0.5in, paperwidth=16.5in, paperheight=9.25in]{geometry} % 1600 x 900 Monitor reading (ThinkPad)
% \usepackage[margin=0.5in, paperwidth=19.9in, paperheight=11.1in]{geometry} % 1920 x 1080 Monitor reading (MultiSync EA234WMi)
% \usepackage[margin=0.5in, paperheight=19.9in, paperwidth=11.1in]{geometry} % 1080 x 1920 Monitor reading (Portrait MultiSync EA234WMi)


\setlength{\columnsep}{1in}
\setlength{\columnseprule}{1px}

\date{\mydate\today}

\title{A parallel implementation of NESTOR in Python 3.4}
\author{Andrew Owen Martin}

%\pagestyle{noweb}

\begin{document}
\maketitle
\tableofcontents

\section{Introduction}

NESTOR is three sets of nodes, retina, memory and matching.
The memory nodes are initialised with a ``model'' pattern, the retina nodes are set with a ``target'' pattern, and the matching nodes will eventually fire in a way that denotes a position of the model on the retina.

Currently this implementation runs each node on a separate process, which doesn't challenge the machine much as they all mostly sleep.

\section{Canonical description}

These are quotes from the paper \cite{nasuto2009communicating}.

\begin{quote}
Matching neurons are fully interconnected to all other matching neurons.
They are also fully connected to both receptor neurons and memory neurons.

The output [of matching neurons] will always consist of (parts of) the accepted spike trains.

Matching neurons both maintain and output hypotheses--`where' values--defining possible locations of the target pattern on the retina.

An active matching neuron will output its current hypothesis as a spike train; an inactive matching neuron will adopt a new hypothesis from the first spike train it receives and output this.

Matching neurons evaluate their hypothesis--`where' value--by comparing randomly selected micro-feature(s)--`what' information--from the memory and the corresponding `what' information from the retina. If the micro-features (the corresponding `what' values) are the same \ldots{} the matching neuron becomes active.

An active matching neuron initiates a spike train and retains its current hypothesis (its `where' value).

A neuron failing to discover the same microfeature will remain inactive and will adopt a new hypothesis encoded in a spike train arriving from other matching neurons.

[I]f the first spike train arrives from memory or retina, a matching neuron will simply output a spike train encoding the position defined by the input trains without further processing of changes to its [notional] state.

A matching neuron only stores the `where' information \ldots{} of an accepted spike train. 

If a neuron is in an active state, it will select for processing the first spike trains from the retina and memory such that $\Delta{}^{w}_{\text{ret}} + \Delta{}^{w}_{\text{mem}} = \Delta{}^{w}_{\text{neur}}$.

If the comparison is successful (i.e. the `what' of the memory neuron matches the `what' of the retina neuron) the matching neuron fires a spike train corresponding to the position defined by its hypothesis $\Delta{}^{w}_{\text{neur}}$.

Otherwise, the matching neuron will become inactive. In the inactive state the matching neuron will accept information from either the first arriving spike train from another matching neuron or spike trains memory and the retina (albeit with no constraints on ISI's). I think this means it does not wait for a pair of spike trains where the `where' parts add up to something specific.

If the first spike train comes from a retina and memory cell then it adds up the `where' parts and emits it. If the first spike comes from a matching cell then it will adopt the `where' part as its hypothesis and become active.
\end{quote}

Other papers that appear to be about NESTOR are
\cite{bishop2017nestor} 
\cite{de2000explorations} 
\cite{de2000attention} 
\cite{morey1999parallel}
\cite{morey2000implementation}.

\section{Finite state machine}

See Table~\ref{tab:fsmtable}.

\begin{table}
	\centering
	\begin{tabular}{cccc|ccc}
		%\toprule{}
		State & Active & Memory & Retina & Retina & Memory & Matching \\
		\midrule
		1&         F   &    F   &   F    &    2   &    3   &    5 \\
		2&         F   &    F   &   T    &    -   &    1   &    - \\
		3&         F   &    T   &   F    &    1   &    -   &    - \\
		4&         F   &    T   &   T    &    X   &    X   &    X \\
		5&         T   &    F   &   F    &    6   &    7   &    - \\
		6&         T   &    F   &   T    &    -   & 5 or 1 &    - \\
		7&         T   &    T   &   F    & 5 or 1 &    -   &    - \\
		8&         T   &    T   &   T    &    X   &    X   &    X \\
		%\bottomrule{}
	\end{tabular}
\caption{`-' is no change, `X' is don't care.}
\label{tab:fsmtable}
\end{table}

\section{Inter-spike Interval (ISI)}

The ISI is read-only so a tuple is a suitable data structure, I've given it the [[origin]] attribute so [[Matching]] neurons can discern where the input came from and hence don't need to have more than one input channel.

<<isi class>>=
`ISI = namedtuple('ISI', ('origin', 'position', 'feature'))
@

<<nestor classes>>=
<<isi class>>
@

\section{Cell classes}

This implementation uses a class hierarchy for cells.
\begin{itemize}
\item [[Cell]] $\rightarrow{}$ [[Matching]]
\item [[Cell]] $\rightarrow{}$ [[DataCell]] $\rightarrow{}$ [[Memory]]
\item [[Cell]] $\rightarrow{}$ [[DataCell]] $\rightarrow{}$ [[Retina]]
\end{itemize}

\subsection{Cell class}

The top cell class just has an [[id_num]] attribute for convenience when logging.

Cells are expected to have a links attribute defined before they're actually ran. This is a list of other cells to which they will send their ISIs.

<<cell class>>=
class `Cell:

	__slots__ = ('id_num','links')

	def __init__(self, id_num):
		self.id_num = id_num

	def __repr__(self):
		return '{name}#{num}'.format(name=self.name.title(),num=self.id_num)
@

<<nestor classes>>=
<<cell class>>
@

\subsection{Data cell class}

Data cells, i.e. Memory and Retina cells have ``where'' and ``what'' attributes.

<<data cell class>>=
class `DataCell(Cell):

	__slots__ = ('where','what')

	def __init__(self, id_num, where, what=None):
		super().__init__(id_num)
		self.where = where
		self.what = what
@

<<nestor classes>>=
<<data cell class>>
@

\subsection{Memory cell}

Memory cells are expected to be set at initialisation, and not changed.
<<memory cell>>=
class `Memory(DataCell):

	name = 'memory'
@

<<nestor classes>>=
<<memory cell>>
@

\subsection{Retina cell}
Retina cells are expected to be periodically updated with [[update_retina]].
<<retina cell>>=
class `Retina(DataCell):
	
	name = 'retina'
@

<<nestor classes>>=
<<retina cell>>
@

\subsection{Wait function}

Returns a number of seconds from a bounded Gaussian distribution. Often used with [[partial]] from the [[functools]] library.

<<wait function>>=
def wait(mean, sigma, min_wait, max_wait):
	return max(
		min(random.gauss(mean,sigma), max_wait),
		min_wait)
@

<<dependencies>>=
import random
@

<<nestor methods>>=
<<wait function>>
@

\subsection{Process cell function}

This function takes a [[DataCell]], 

<<process cell function>>=
def process_cell(cell, mean, sigma, min_wait, max_wait):
	''' Take a DataCell, and some variables defining firing rate'''

	sleep_time = partial(wait, mean, sigma, min_wait, max_wait)	

	while True:

		next_wait = sleep_time() 

		time.sleep(next_wait)

		isi = ISI(origin=cell.name, position=cell.where, feature=cell.what)


		for connection in cell.links:

			try:	

				connection.receptor.put(isi,block=False)

			except queue.Full:

				pass
@


<<nestor methods>>=
<<process cell function>>
@

\subsection{Matching cell}

Class definition for the Matching cell. Retina and Memory store data received from their respective channels.

<<matching cell>>=
class `Matching(Cell):

	name = 'matching'

	__slots__ = ('retina','memory','hypothesis','receptor')

	max_input_isi_count = 1

	def __init__(
		self,
		id_num,
		retina=None,
		memory=None,
		hypothesis=None,
		receptor=None,
	):
		'''id_num = convenience identifier
		Ignore all the other attributes, unless you're copying the
		Matching cell as they'll be set during processing.
		receptor will be set during initialisation.'''

		super().__init__(id_num)
		self.retina = retina
		self.memory = memory
		self.hypothesis = hypothesis
		if receptor is None:
			receptor = Queue(maxsize=Matching.max_input_isi_count)
		self.receptor = receptor
@

<<nestor classes>>=
<<matching cell>>
@

\subsection{Process matching cell}
<<process matching cell>>=
def process_matching(
	cell,
	mean,
	sigma,
	min_wait,
	max_wait,
	memory_cell_count,
	retina_cell_count):

	not_listening_time = datetime.now()

	sleep_time = partial(wait, mean, sigma, min_wait, max_wait)	

	process_signal = partial(
		update_matching,
		cell,
		memory_cell_count=memory_cell_count,
		retina_cell_count=retina_cell_count,)

	while True:

		signal = cell.receptor.get()

		if False and datetime.now() < not_listening_time:
			continue

		output = process_signal(signal)

		if output:

			matching_fire(cell, output)

			not_listening_time = (
				datetime.now()
				+ timedelta(0,sleep_time(),),)
@

<<dependencies>>=
import time
import queue
@

<<nestor methods>>=
<<process matching cell>>
@

\subsection{Matching fire function}
<<matching fire function>>=
def matching_fire(cell, output):

	log.info('{cell} fires {output}'.format(cell=cell, output=output))

	isi = ISI(origin=cell.name, position=output, feature=None,)

	for connection in cell.links:

		try:	

			connection.receptor.put(isi,block=False)

		except queue.Full:

			pass
@

<<nestor methods>>=
<<matching fire function>>
@

\subsection{Update matching cell}
<<update matching cell>>=
def update_matching(cell, signal, memory_cell_count, retina_cell_count):

	fire = None

	if cell.hypothesis is None: # 1,2,3

		<<update inactive matching cell>>

		if cell.memory and cell.retina:

			fire = cell.retina + cell.memory

			cell.memory = None
			cell.retina = None

	else: # 5,6,7

		<<update active matching cell>>

		if cell.memory and cell.retina:

			if not (cell.memory.feature == cell.retina.feature):

				cell.hypothesis = None

			else:

				fire = cell.hypothesis

			cell.memory = None
			cell.retina = None

	return fire
@

<<nestor methods>>=
<<update matching cell>>
@

\subsection{Update inactive matching cell}
<<update inactive matching cell>>=
if cell.memory is None:

	if cell.retina is None: #1

		if signal.origin == Retina.name: # Go from 1 to 2

			cell.retina = signal.position

		elif signal.origin == Memory.name: # Go from 1 to 3

			cell.memory = signal.position

		elif signal.origin == Matching.name: # Go from 1 to 5

			cell.hypothesis = signal.position

			fire = cell.hypothesis

	elif signal.origin == Memory.name: #2

		cell.memory = signal.position # Go from 2 to 1

elif signal.origin == Retina.name: #3

	cell.retina = signal.position # Go from 3 to 1
@

\subsection{Update active matching cell}
<<update active matching cell>>=
if cell.memory is None:

	if cell.retina is None: #5

		if signal.origin == Retina.name: # Go from 5 to 6

			if (
				signal.position >= cell.hypothesis
				or (signal.position + memory_cell_count < cell.hypothesis)
			):

				pass

			elif signal.position < cell.hypothesis:

				cell.retina = signal

		elif signal.origin == Memory.name:

			if (
				signal.position >= cell.hypothesis
				or (signal.position + retina_cell_count < cell.hypothesis)
			):

				cell.hypothesis = None # Go from 5 to 1

			elif signal.position < cell.hypothesis: # Go from 5 to 7

				cell.memory = signal

	elif( #6
		signal.origin == Memory.name
		and (cell.retina.position + signal.position == cell.hypothesis)
	):

		cell.memory = signal # Go from 6 to 5 or 1

		if signal is None:
			raise RuntimeError('signal is none')

elif ( #7
	signal.origin == Retina.name
	and (cell.memory.position + signal.position == cell.hypothesis)
):

	cell.retina = signal # Go from 7 to 5 or 1
@

\section{Network}

\subsection{Network named tuple}
<<network class>>=
`Network = namedtuple('Network',('retina','memory','matching'))
@

<<nestor classes>>=
<<network class>>
@

\subsection{Make Network function}

Constructs all the retina cells, then the memory cells, then the matching cells, then links all the data cells to the matching cells and all the matching cells to all the other matching cells.

At the end of this function you get a [[Network]] where all the [[Retina]] cells have [[None]] as their features, they need to be initialised with [[update_retina]].

<<make network function>>=
def make_network(retina_count, matching_count, memory_features):

	retina_cells = [
		Retina(id_num=retina_num, where=retina_count - retina_num,)
		for retina_num
		in range(retina_count)
	]

	memory_cells = [
		Memory(id_num=memory_num, where=memory_num, what=feature,)
		for memory_num, feature
		in enumerate(memory_features, start=1)
	]

	matching_cells = [
		Matching(id_num=matching_num)
		for matching_num
		in range(matching_count)
	]

	# Link all data (memory and retina) cells to all matching cells.
	for data_cell in chain(retina_cells, memory_cells):
		data_cell.links = matching_cells

	# Link all matching cells to all other matching cells.
	for num, matching in enumerate(matching_cells):
		others = matching_cells[:num] + matching_cells[num+1:]
		matching.links = others

	return Network(
		retina=retina_cells,
		matching=matching_cells,
		memory=memory_cells,)
@

<<nestor methods>>=
<<make network function>>
@

\subsection{Update retina function}

Sets the features of the [[Retina]] cells of a [[Network]].

<<update retina function>>=
def update_retina(network, retina_features):
	for cell, feature in zip(network.retina, retina_features):
		cell.what = feature
@

<<nestor methods>>=
<<update retina function>>
@

\subsection{Run network function}
<<run network function>>=
def run_network(network):

	cell_worker = partial(
		process_cell,
		mean=1.5,
		sigma=0.5,
		min_wait=0.1,
		max_wait=10)

	static_cell_processes = [
		Process(target=cell_worker, args=(cell,), daemon=True)
		for cell
		in chain(network.retina, network.memory)
	]

	matching_worker = partial(
		process_matching,
		mean=1.5,
		sigma=0.5,
		min_wait=0.1,
		max_wait=10,
		memory_cell_count=len(network.memory),
		retina_cell_count=len(network.retina),)

	matching_cell_processes = [
		Process(target=matching_worker, args=(cell,), daemon=True)
		for cell
		in network.matching
	]

	[
		process.start()
		for process 
		in chain(static_cell_processes,	matching_cell_processes,)
	]

	# The program doesn't exit until <enter> is pressed.
	input()
@

<<dependencies>>=
from multiprocessing import Process, Queue
from functools import partial
from itertools import chain
@

<<nestor methods>>=
<<run network function>>
@

\section{Front end}
<<front end>>=
description = (
	"Run a NESTOR, mostly as a library"
)

if __name__ == '__main__':
	parser = argparse.ArgumentParser(
		description=description,
	)

	# Args go here

	args = parser.parse_args()

	retina_count=100

	retina_features, memory_features = random_task(
		retina_count=retina_count,
		memory_count=10,
		noise_count=0,
	)

	network = make_network(
		retina_count=retina_count,
		matching_count=10,
		memory_features=memory_features,)

	update_retina(network=network, retina_features=retina_features,)

	run_network(network)
@

<<dependencies>>=
import argparse
@

\subsection{Random task function}
<<random task function>>=
def random_task(retina_count, memory_count, noise_count):

	colours = ('black','blue','green','red','yellow','orange',
		'purple','teal','white','brown')
	
	retina_features = tuple(
		random.choice(colours)
		for _
		in range(retina_count)
	)

	mem_num = max(0,(retina_count//2)-memory_count)

	memory_features = retina_features[mem_num:mem_num+memory_count]

	# Add noise.
	for wrong_num in random.sample(range(memory_count),noise_count):
		wrong_feature = retina_features[wrong_num]
		while wrong_feature == retina_features[wrong_num]:
			wrong_feature = random.choice(colours)
		retina_features = (
			retina_features[:wrong_num]
			+ (wrong_feature,)
			+ retina_features[wrong_num+1:])

	return retina_features, memory_features
@

<<nestor methods>>=
<<random task function>>
@

\section{Library definition}
<<nestor.py>>=
#!/usr/bin/env python
# -*- coding: utf-8 -*-
<<dependencies>>
from collections import namedtuple
from datetime import datetime
from datetime import timedelta
from itertools import chain
import random
import time
<<init logging>>
<<nestor classes>>
<<nestor methods>>
<<front end>>
@

\subsection{Logging}
<<init logging>>=
log.basicConfig(level=log.INFO)
@

<<dependencies>>=
import logging as log
@

\bibliography{/home/amartin/sds_repository/bib/journal_publications,/home/amartin/sds_repository/bib/technical_reports,/home/amartin/sds_repository/bib/workshops_and_other_publications}
\bibliographystyle{plain}

\appendix{}

\section{Index}

\nowebindex{}

\section{Code Chunks}

\nowebchunks{}

\end{document}

